{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-04T10:29:36.783840Z",
     "start_time": "2023-12-04T10:29:34.572058Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class TextGraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, edge_indices, labels, tokenizer_name='roberta-base'):\n",
    "        \"\"\"\n",
    "        texts: 句子列表\n",
    "        edge_indices: 关系列表\n",
    "        labels: 标签列表\n",
    "        tokenizer_name: 使用的预训练tokenizer名称\n",
    "        \"\"\"\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.texts = texts\n",
    "        self.edge_indices = edge_indices\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        edge_index = self.edge_indices[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # 去除批次维度\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
    "\n",
    "        return input_ids, attention_mask, edge_index, label\n",
    "    \n",
    "    \n",
    "class GATConvWithAttention(GATConv):\n",
    "    def forward(self, x, edge_index, edge_attr=None, size=None, return_attention_weights=True):\n",
    "        out, attention_weights = super().forward(x, edge_index, edge_attr, size, return_attention_weights)\n",
    "        return out, attention_weights\n",
    "\n",
    "\n",
    "class RobertaGAT(nn.Module):\n",
    "    def __init__(self, roberta_model_name, num_classes):\n",
    "        super(RobertaGAT, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
    "        self.gat = GATConvWithAttention(self.roberta.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, edge_index):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        gat_output, attention_weights = self.gat(sentence_embeddings, edge_index)\n",
    "        return F.log_softmax(gat_output, dim=1), attention_weights\n",
    "\n",
    "# 初始化模型\n",
    "model = RobertaGAT(\"roberta-base\", num_classes=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T10:59:13.994958Z",
     "start_time": "2023-12-04T10:59:09.745426Z"
    }
   },
   "id": "de9d2d2ed033e6c9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 图关系\n",
    "# 训练集(71251,4519)\n",
    "import pandas as pd\n",
    "def get_edge_index(path, num, type):\n",
    "        # df = pd.read_csv('data/train.tsv', sep='\\t')  # 训练集(71251,4519)\n",
    "        # df = pd.read_csv('data/test.tsv', sep='\\t')   # 测试集合(15250,965)\n",
    "        # df = pd.read_csv(\"data/validation.csv\")  # 验证集 (16073,1028)\n",
    "    df = ''\n",
    "    if type == 'csv':\n",
    "        df = pd.read_csv(path)\n",
    "    elif type == 'tsv':\n",
    "        df = pd.read_csv(path, sep='\\t')\n",
    "    relationship = []\n",
    "    for i in range(0, len(df['label'])):\n",
    "        relationship.append([i, num])\n",
    "        try:\n",
    "            if df['label'][i] == 'conclusions' and df['label'][i+1] == 'background':\n",
    "                num += 1\n",
    "                continue\n",
    "        except KeyError:\n",
    "            break\n",
    "        relationship.append([i, i+1])\n",
    "    edge_index = torch.tensor(relationship)\n",
    "    return edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T10:29:43.633949Z",
     "start_time": "2023-12-04T10:29:43.589625Z"
    }
   },
   "id": "337f5c87ce2eea22"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cd691599529443bb931c993c9bef2ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6c2d6a458c54b9dbf234c131b3778d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdead7918ef44b6a9d91ddc4f9d1f1cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 加载数据集\n",
    "dataset_train = load_dataset('csv', data_files='data/train.tsv', delimiter='\\t')\n",
    "dataset_test = load_dataset('csv', data_files='data/test.tsv', delimiter='\\t')\n",
    "dataset_valid = load_dataset('csv', data_files='data/validation.csv')\n",
    "dataset = DatasetDict({'train': dataset_train, 'test': dataset_test, 'validation': dataset_valid})\n",
    "# 获取关系\n",
    "train_rel = get_edge_index(path='data/train.tsv', num=71251, type='tsv')\n",
    "text_rel = get_edge_index(path='data/test.tsv', num=15250, type='tsv')\n",
    "valid_rel = get_edge_index(path='data/validation.csv', num=16073, type='csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T10:58:01.503213Z",
     "start_time": "2023-12-04T10:57:55.634836Z"
    }
   },
   "id": "14b5c2fea9293287"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/71251 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4057d4ed518847f680274020e3e5ec22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/15250 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1d791d648bb4388944527df4db26c9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/16073 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b17e4de1a57147448318f15976e9a77f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "def encode_batch(batch):\n",
    "    return RobertaTokenizer(batch['text'], padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "dataset = {split: dataset[split].map(encode_batch, batched=True) for split in dataset.keys()}\n",
    "\n",
    "data_split = dataset['train'] \n",
    "\n",
    "input_ids = torch.stack(tuple(data_split['input_ids']))\n",
    "attention_mask = torch.stack(tuple(data_split['attention_mask']))\n",
    "\n",
    "edge_index = train_rel\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T11:16:14.284617Z",
     "start_time": "2023-12-04T11:15:36.050920Z"
    }
   },
   "id": "b8943632c32c1976"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 假设标签\n",
    "labels = torch.tensor([0, 1], dtype=torch.long)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "# 训练循环\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_ids, attention_mask, edge_index)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T11:22:12.875401Z",
     "start_time": "2023-12-04T11:22:03.545964Z"
    }
   },
   "id": "29ac6c20a23db9d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
